import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.Consumed;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.KafkaStreams.State;
import org.apache.kafka.streams.KeyValue;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.kstream.Joined;
import org.apache.kafka.streams.kstream.KStream;
import org.apache.kafka.streams.kstream.KTable;
import org.apache.kafka.streams.kstream.Produced;
import org.apache.kafka.streams.kstream.Transformer;
import org.apache.kafka.streams.processor.ProcessorContext;
import org.apache.kafka.streams.state.KeyValueStore;
import org.apache.kafka.streams.state.StoreBuilder;
import org.apache.kafka.streams.state.Stores;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

  private KafkaStreams processStreams(final String bootstrapServers, final String stateDir) {

    //Latch onto instances of the CALLS and CALLS topics
    final StreamsBuilder builder = new StreamsBuilder();
    final KStream<String, Calls> CALLS = builder
        .stream(Topics.CALLS.name(),
            Consumed.with(Topics.CALLS.keySerde(), Topics.CALLS.valueSerde()));
    final KTable<agentId, Integer> warehouseCALLS = builder
        .table(Topics.WAREHOUSE_CALLS.name(), Consumed
            .with(Topics.WAREHOUSE_CALLS.keySerde(), Topics.WAREHOUSE_CALLS.valueSerde()));
            
    return new KafkaStreams(builder.build(),
        MicroserviceUtils.baseStreamsConfig(bootstrapServers, stateDir, CALLS_SERVICE_APP_ID));
  }

  private static class CALLSValidator implements
      Transformer<Product, KeyValue<Calls, Integer>, KeyValue<String, CallsValidation>> {

    private KeyValueStore<Product, Long> reservedStocksStore;
   }

public static void main(final String[] args) throws Exception {
    final CALLService service = new CALLService();
    service.start(parseArgsAndConfigure(args));
    addShutdownHookAndBlock(service);
  }
}
